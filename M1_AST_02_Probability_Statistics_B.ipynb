{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"DCgpE0GSFT8a"},"source":["# Advanced Certification Program in Deep Learning\n","## A program by IISc and TalentSprint\n","### Assignment 2: Probability and Statistics "]},{"cell_type":"markdown","metadata":{"id":"pr0NVbjeFYi5"},"source":["## Learning Objectives"]},{"cell_type":"markdown","metadata":{"id":"lP9uVe1wp5j6"},"source":["At the end of the experiment, you will be able to\n","\n","* get a broad exposure of the estimators and the way to deal them\n","* understand the concepts of probability distributions\n","* understand marginal probability\n","* understand the terms like parameter estimation and bias estimator\n","* understand the concepts of mean squared error, correlation and maximum likelihood estimation\n","*   understand the bayesian inference with prior and posterior distributions"]},{"cell_type":"markdown","metadata":{"id":"BNLA8HiKxQhc"},"source":["### Setup Steps:"]},{"cell_type":"code","metadata":{"id":"2YzfoPvJDiTX"},"source":["#@title Please enter your registration id to start: { run: \"auto\", display-mode: \"form\" }\n","Id = \"\" #@param {type:\"string\"}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rEzlYL4CDrmE"},"source":["#@title Please enter your password (normally your phone number) to continue: { run: \"auto\", display-mode: \"form\" }\n","password = \"\" #@param {type:\"string\"}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cellView":"form","id":"GXbNUL2L6LoU"},"source":["#@title Run this cell to complete the setup for this Notebook\n","from IPython import get_ipython\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","ipython = get_ipython()\n","  \n","notebook= \"M1_AST_02_Probability_Statistics_B\" #name of the notebook\n","\n","def setup():\n","    ipython.magic(\"sx wget https://cdn.iisc.talentsprint.com/DLFA/Experiment_related_data/Customer_Churn.csv\")\n","    from IPython.display import HTML, display\n","    display(HTML('<script src=\"https://dashboard.talentsprint.com/aiml/record_ip.html?traineeId={0}&recordId={1}\"></script>'.format(getId(),submission_id)))\n","    print(\"Setup completed successfully\")\n","    return\n","\n","def submit_notebook():\n","    ipython.magic(\"notebook -e \"+ notebook + \".ipynb\")\n","    \n","    import requests, json, base64, datetime\n","\n","    url = \"https://dashboard.talentsprint.com/xp/app/save_notebook_attempts\"\n","    if not submission_id:\n","      data = {\"id\" : getId(), \"notebook\" : notebook, \"mobile\" : getPassword()}\n","      r = requests.post(url, data = data)\n","      r = json.loads(r.text)\n","\n","      if r[\"status\"] == \"Success\":\n","          return r[\"record_id\"]\n","      elif \"err\" in r:        \n","        print(r[\"err\"])\n","        return None        \n","      else:\n","        print (\"Something is wrong, the notebook will not be submitted for grading\")\n","        return None\n","    \n","    elif getAnswer1() and getAnswer2() and getComplexity() and getAdditional() and getConcepts() and getComments() and getMentorSupport():\n","      f = open(notebook + \".ipynb\", \"rb\")\n","      file_hash = base64.b64encode(f.read())\n","\n","      data = {\"complexity\" : Complexity, \"additional\" :Additional, \n","              \"concepts\" : Concepts, \"record_id\" : submission_id, \n","              \"answer1\" : Answer1, \"answer2\" : Answer2, \"id\" : Id, \"file_hash\" : file_hash,\n","              \"notebook\" : notebook,\n","              \"feedback_experiments_input\" : Comments,\n","              \"feedback_mentor_support\": Mentor_support}\n","      r = requests.post(url, data = data)\n","      r = json.loads(r.text)\n","      if \"err\" in r:        \n","        print(r[\"err\"])\n","        return None   \n","      else:\n","        print(\"Your submission is successful.\")\n","        print(\"Ref Id:\", submission_id)\n","        print(\"Date of submission: \", r[\"date\"])\n","        print(\"Time of submission: \", r[\"time\"])\n","        print(\"View your submissions: https://dlfa-iisc.talentsprint.com/notebook_submissions\")\n","        #print(\"For any queries/discrepancies, please connect with mentors through the chat icon in LMS dashboard.\")\n","        return submission_id\n","    else: submission_id\n","    \n","\n","def getAdditional():\n","  try:\n","    if not Additional: \n","      raise NameError\n","    else:\n","      return Additional  \n","  except NameError:\n","    print (\"Please answer Additional Question\")\n","    return None\n","\n","def getComplexity():\n","  try:\n","    if not Complexity:\n","      raise NameError\n","    else:\n","      return Complexity\n","  except NameError:\n","    print (\"Please answer Complexity Question\")\n","    return None\n","  \n","def getConcepts():\n","  try:\n","    if not Concepts:\n","      raise NameError\n","    else:\n","      return Concepts\n","  except NameError:\n","    print (\"Please answer Concepts Question\")\n","    return None\n","  \n","  \n","# def getWalkthrough():\n","#   try:\n","#     if not Walkthrough:\n","#       raise NameError\n","#     else:\n","#       return Walkthrough\n","#   except NameError:\n","#     print (\"Please answer Walkthrough Question\")\n","#     return None\n","  \n","def getComments():\n","  try:\n","    if not Comments:\n","      raise NameError\n","    else:\n","      return Comments\n","  except NameError:\n","    print (\"Please answer Comments Question\")\n","    return None\n","  \n","\n","def getMentorSupport():\n","  try:\n","    if not Mentor_support:\n","      raise NameError\n","    else:\n","      return Mentor_support\n","  except NameError:\n","    print (\"Please answer Mentor support Question\")\n","    return None\n","\n","def getAnswer1():\n","  try:\n","    if not Answer1:\n","      raise NameError \n","    else: \n","      return Answer1\n","  except NameError:\n","    print (\"Please answer Question 1\")\n","    return None\n","\n","def getAnswer2():\n","  try:\n","    if not Answer2:\n","      raise NameError \n","    else: \n","      return Answer2\n","  except NameError:\n","    print (\"Please answer Question 2\")\n","    return None\n","  \n","\n","def getId():\n","  try: \n","    return Id if Id else None\n","  except NameError:\n","    return None\n","\n","def getPassword():\n","  try:\n","    return password if password else None\n","  except NameError:\n","    return None\n","\n","submission_id = None\n","### Setup \n","if getPassword() and getId():\n","  submission_id = submit_notebook()\n","  if submission_id:\n","    setup() \n","else:\n","  print (\"Please complete Id and Password cells before running setup\")\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fuXwHNEXFntd"},"source":["### Importing required packages"]},{"cell_type":"code","metadata":{"id":"vJnhXhDAFTHj"},"source":["import numpy as np\n","import pandas as pd\n","import math\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import scipy\n","import scipy.stats as stats\n","from numpy import random\n","from scipy.stats import beta, binom, expon, multivariate_normal, bernoulli, poisson\n","sns.set_style('whitegrid')\n","\n","sns.set(style='ticks', palette='Set2')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hhboyEyVi0Ka"},"source":["### Probability Distributions"]},{"cell_type":"markdown","metadata":{"id":"tI8czPIjk_yy"},"source":["**Probability distribution**:- It is a statistical function that describes all the possible values and likelihoods that a random variable can take within a given range.\n","There are many types of Probability distribution,such as:-\n","\n","*   Bernoulli Distribution\n","*   Binomial Distribution\n","*   Multivariate Normal Distributions\n","*   Poisson Distribution\n","*   Exponential Distribution\n"]},{"cell_type":"markdown","metadata":{"id":"RudTJq80nyxl"},"source":["### Bernoulli Distribution"]},{"cell_type":"markdown","metadata":{"id":"lc-0orK-n7YD"},"source":["**Bernoulli Distribution**:- It is a discrete distribution having two possible outcomes labeled by n=0 and n=1 in which n=1 (\"success\") occurs with probability p and n=0 (\"failure\") occurs with probability q=1-p, where 0<p<1. The outcome is either 0 or 1 always.\n","\n","Probability mass function of Bernoulli distribution is :-\n","$ P(n)=p^{n}(1-p)^{(1-n)}$ \t\n","\n","\n","To understand more click [here](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.bernoulli.html)\n"]},{"cell_type":"markdown","metadata":{"id":"7-BPEXe4pWen"},"source":["**Exercise 1:** Create a Bernoulli distributed discrete random variable plot a graph using the achieved data."]},{"cell_type":"code","metadata":{"id":"dXp_URtKn69t"},"source":["# Creating a data of size 10000 and with the probability success as half i.e 0.2\n","data_bernoulli = bernoulli.rvs(size=10000, p=0.2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MsmbVXE6seFi"},"source":["ax= sns.distplot(data_bernoulli,kde=False)\n","ax.set(xlabel='Bernoulli Distribution', ylabel='Frequency');"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"b4xdFCu40EXK"},"source":["### Binomial Distribution"]},{"cell_type":"markdown","metadata":{"id":"98KYXjiH69XT"},"source":["**Binomial Distribution**:- It is defined as when there is only one outcome for each trail, that each trail has the same probability of success, and that each trial is mutually exclusive or independent of the other.\n","\n"," Its probability distribution function is given by :\n"," \n","$f(k,n,p) = Pr(k;n,p) = Pr(X=k) =\\begin{pmatrix}\n","n \\\\\n","k \n","\\end{pmatrix} p^k(1-p)^{n-k}$\n","\n","\n","\n","\n","where :\n","$\\binom{n}{k} = \\frac{n!}{k!(n-k)!}$\n","\n","\n","To understand more click [here](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.binom.html)\n"]},{"cell_type":"markdown","metadata":{"id":"OOtBKAed_A5X"},"source":["**Exercise 2**:\n","Generate a binominal distributed random data and plot it."]},{"cell_type":"code","metadata":{"id":"8wjlntYY9Km_"},"source":["# Creating the binominal distribution data where, n is the number of trails, p is the p probability, size is the shape of random variates.\n","data_binom = binom.rvs(n=200, p=0.6, size=1000)\n","\n","# Ploting the graph\n","# YOUR CODE HERE"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Practical example explaining use case of binomial distribution"],"metadata":{"id":"jmfIjgzaY4ty"}},{"cell_type":"markdown","source":["\n"," There are 10 sets of traffic lights on the journey.The probability that a driver must stop at any one traffic light coming to airport is 0.25\n"," \n","(a) What is the probability that a driver must stop at exactly 2 of the 10 sets of traffic lights?\n","\n","(b) What is the probability that a driver will be stopped at 1 or more of the 10 sets of traffic lights?"],"metadata":{"id":"8DdUE7kCZEMj"}},{"cell_type":"markdown","source":["**(a) What is the probability that a driver must stop at exactly 2 of the 10 sets of traffic lights?**\n","\n","Here we have to calculate the probablity that particular event happens exactly two times\n","\n","$$ P(X = 2) = {\\binom{10}{2}\\cdot(0.25)^2\\cdot(1-0.25)^8}.$$"],"metadata":{"id":"M5GQc807zfV_"}},{"cell_type":"code","source":["n = 10   # Number of times experiment runs\n","p = 0.25 # Probability of outcome(here driver stopping at traffic light)\n","k = 2    # Number of successful trails(given n trails)\n","pmf_binomial = stats.binom.pmf(k,n,p) # Probability mass function for k = 2 i.e. P(X=2)\n","print(f\"Probability that a driver stops at exactly 2 out of the 10 traffic lights is  {round(pmf_binomial,4)}\")"],"metadata":{"id":"nL0PgofRYxo5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["To understand more about ***stats.binom.pmf()*** method and its usage [click here](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.binom.html#scipy.stats.binom)"],"metadata":{"id":"soq_0UXg19Uf"}},{"cell_type":"markdown","source":["**(b) What is the probability that a driver will be stopped at 1 or more of the 10 sets of traffic lights?**\n","\n","Here we have to calculate the probablity that particular event happens one or more times i.e. $ P(X≥1) $ or $ [1- P(X=0)] $\n","\n","$$ P(X ≥ 1) = 1 - [{\\binom{10}{0}\\cdot(0.25)^0\\cdot(1-0.25)^{10} }].$$"],"metadata":{"id":"hK9oR1Bt3z4g"}},{"cell_type":"code","source":["n = 10   # Number of times experiment runs\n","p = 0.25 # Probability of outcome(here driver stopping at traffic light)\n","k = 0    # Number of successful trails(given n trails)\n","cumbinomial = stats.binom.cdf(k,n,p) # P(X>=1) or 1-P(X=0)\n","print(f\"Probability that driver will be stopped at 1 or more of 10 sets of traffic lights is {round(1-cumbinomial,4)}\")  "],"metadata":{"id":"EPYBDYYWbq0H"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["To understand more about ***stats.binom.cdf()*** method and its usage [click here](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.binom.html#scipy.stats.binom)"],"metadata":{"id":"_Cma9n3y9Shg"}},{"cell_type":"markdown","metadata":{"id":"eEiL34epPdIq"},"source":["### Poisson Distribution"]},{"cell_type":"markdown","metadata":{"id":"gkasrxKDPhBG"},"source":["**Poisson Distribution**:- The Poisson distribution is used to model the number of events occurring within a given time interval. The formula for the Poisson probability mass function is.\n","\n","$P(x; μ) = (e^{-μ} * μ^{x}) / x!$\n","\n","To understand more click [here](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.poisson.html)"]},{"cell_type":"markdown","metadata":{"id":"7VODgItpRb2d"},"source":["**Exercise 3:-** Generate a Poisson random data and plot it."]},{"cell_type":"code","metadata":{"id":"416-P14YRAem"},"source":["# Generate random normalized data\n","mu = 10  # Sample mean value\n","data_poisson = poisson.rvs(mu, size=1000)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IGgI7z4aRPDp"},"source":["# Ploting the graph\n","# YOUR CODE HERE"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Practical example for Poisson distribution"],"metadata":{"id":"aksxK17E-bj6"}},{"cell_type":"markdown","source":["The number of work related injuries per month in a manufacturing plant is known to follow a Poisson distribution, with a mean of 2.5 work-related injuries a month.\n","\n","a) What is the probability that in a given month, no work-related injuries occur?\n","\n","b) That at least two work- related injury occurs?"],"metadata":{"id":"oIkBRWLE-bj8"}},{"cell_type":"markdown","source":["**(a) What is the probability that in a given month, no work-related injuries occur?**\n","\n","Here we have to calculate the probablity that given month has,no work related injuries using probability mass function\n","\n","$$ P(X = 0) = \\frac{(e^{-2.5} * 2.5^{0})} {0!}\n"," $$\n"," $$ P(X = 0) = 0.08208 $$"],"metadata":{"id":"uNmPPbmrC4Hh"}},{"cell_type":"code","source":["# Calculate probability using pmf\n","# YOUR CODE HERE"],"metadata":{"id":"Jym0quTc-bj-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["To understand more about ***stats.poisson.pmf()*** method and its usage [click here](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.poisson.html?highlight=stats%20poisson%20cdf)"],"metadata":{"id":"IIlaLklUGZu8"}},{"cell_type":"markdown","source":["**b) That at least two work- related injury occurs?**\n","\n","Here we have to calculate the probablity that given month has,two or more related injuries\n","\n","$$ P(X >=2 ) = 1 - [P(X <2 ) $$\n","$$ P(X >=2 ) = 1 - [P(X = 0) +P(X=1)] $$\n","$$ P(X >=2 ) = 1 - [\\frac{(e^{-2.5} * 2.5^{0})} {0!}  +   \\frac{(e^{-2.5} * 2.5^{1})} {1!}]\n"," $$\n"," $$ P(X >=2 ) = 0.7127025048163542 $$"],"metadata":{"id":"_xwbsVceEE6k"}},{"cell_type":"code","source":["# Calculating probability using CDF\n","cumulative_binomial = stats.poisson.cdf(k=1, mu=2.5) # P(X>=2) or 1-P(X=0)-P(X=1)\n","print(f\"Probability that least two work-related injury occurs i.e P(X>=2) is {round(1-cumulative_binomial,4)}\")"],"metadata":{"id":"USRlgPGN-bkA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["To understand more about ***stats.poisson.cdf()*** method and its usage [click here](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.poisson.html?highlight=stats%20poisson%20cdf)"],"metadata":{"id":"e8nbF46sGG0S"}},{"cell_type":"markdown","metadata":{"id":"iZWE-hMeRpMJ"},"source":["### Exponential Distribution"]},{"cell_type":"markdown","metadata":{"id":"aJflrxWsRrTr"},"source":["**Exponential Distribution:-**A continuous random variable $X$ is said to have an exponential distribution with parameter $λ>0$, shown as $X∼Exponential(λ)$, if its PDF is given by \\begin{equation}\n","             \\nonumber f_X(x) = \\left\\{\n","              \\begin{array}{l l}\n","                \\lambda e^{-\\lambda x} & \\quad  x > 0\\\\\n","                0 & \\quad \\textrm{otherwise}\n","              \\end{array} \\right.\n","            \\end{equation}\n","To understand more, click [here](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.expon.html)."]},{"cell_type":"markdown","metadata":{"id":"q5Vijtd8TN8G"},"source":["**Exercise 4:-** Generate Exponential random data and plot it."]},{"cell_type":"code","metadata":{"id":"mL5zD7eaTldp"},"source":["# Generate random normalised data \n","data_expon = expon.rvs(size=1000)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3qDS-BMbTnsm"},"source":["ax = sns.distplot(data_expon,\n","                  kde=True,\n","                  bins=100,\n","                  color='skyblue',\n","                  hist = True)\n","ax.set(xlabel='Exponential Distribution', ylabel='Frequency');"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7tcOY6WdfWwZ"},"source":["### Multivariate Normal Distributions"]},{"cell_type":"markdown","metadata":{"id":"G4kaCH6xXhuD"},"source":["A vector-valued random variable $X =[X_1 · · · X_n]^{T}$ is said to have a multivariate normal (or Gaussian) distribution with mean $µ ∈ R^{n} $\n","if its square of probability density function\n","is given by\n","\n","<center>\n","$y=f(x,\\mu,\\sum) =  \\frac{1}{\\sqrt{(2 \\pi)^k det\\sum}} exp(-\\frac{1}{2}(x-\\mu)^{T}\\sum^{-1}(x-\\mu))$\n","</center>\n","\n","\n","\n","We write this as $X ∼ N (\\mu, \\sum)$. \n","\n","To understand more, click [here](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.multivariate_normal.html)."]},{"cell_type":"markdown","metadata":{"id":"ziXcZXHmfTgH"},"source":["**Exercise 5:-** \n","Generate Multivariate normal random data and plot it."]},{"cell_type":"code","metadata":{"id":"aL3wbIxigxWX"},"source":["# Generate random normalized data\n","data_multivariate_normal = multivariate_normal.rvs(size=1000)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mRc2ojKEhBYQ"},"source":["# Ploting the graph\n","# YOUR CODE HERE"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5RK1KhmWZhRb"},"source":["### Covariance\n","\n","Covariance is a measure of how much two random variables vary together. It is similar to variance.But variance tells you how a single variable varies and covariance tells you how two variables vary together.\n","\n","To calculate covariance we can use the formula as follows:\n","\n","$Cov(x,y) = \\frac{\\sum (x_{i}-x_{m})(y_{i}-y_{m})}{n-1}$"]},{"cell_type":"markdown","metadata":{"id":"RQOEiD10ZhRg"},"source":["1. A company has a data set for five-quarters that represents the following:\n","\n","  a) x = Gross Domestic Product (GDP) growth of each quarter in percent\n","  \n","  b) y = Advancement of the company's latest product in percent\n","  \n","  The five-quarters dataset for x and y is given below:\n","\n","  x = 2, y = 10\n","\n","  x = 3, y = 14\n","\n","  x = 2.7, y = 12\n","\n","  x = 3.2, y = 15\n","\n","  x = 4.1, y = 20\n","\n","  Find the covariance of x and y using the above dataset?"]},{"cell_type":"code","metadata":{"id":"GqCSmT5yZhRj"},"source":["# Declaring the parameters x and y of the dataset to find the covariance\n","x = [2,3,2.7,3.2,4.1]\n","y = [10,14,12,15,20]\n","\n","# Covariance of x and y using cov() \n","print(\"Variance of x:\",np.cov(x))\n","print(\"Variance of y:\",np.cov(y))\n","print(\"Covariance of x and y:\\n\",np.cov(x,y))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8Kl8JaQMZhRl"},"source":["A positive value of covariance shows that new product's growth has a positive relationship with quaterly GDP growth. "]},{"cell_type":"markdown","metadata":{"id":"qBZ7dLAqZ4xx"},"source":["### Marginal Probability"]},{"cell_type":"markdown","metadata":{"id":"dBKdMd3oZ4x6"},"source":["The probability of an event that occurs irrespective of the outcome of another event is known as Marginal probability. It is used in the scenarios where we are interested in calculating the probability of an event for a random variable not taking into account the outcome of another random variable.\n","\n","For example, the probability of $X = E_{A}$ for total outcomes of Y.\n","\n","We can calculate the Marginal Probability as follows:\n","\n","$P(X=A) = \\sum  P(X=A, Y=y_{i})$ for all y.\n","\n","This denotes that for a given fixed event $A$, the marginal probability is simply the sum or union of all the probability of all events for the second variable $y$.\n"]},{"cell_type":"markdown","metadata":{"id":"vsTnQcAqZ4yH"},"source":["1. There are three bags colored \"**black**\" \"**white**\" and \"**grey**\"containing \"**green**\" and \"**orange**\" balls in all three of them. The black bag contains 4 orange and 12 green balls. Next, the white bag contains 18 green and 6 orange balls. Further, the grey bag contains 8 orange and 24 green balls. Consider that the probability of picking up the balls from black, white, grey bag are 0.36, 0.28 and 0.44 respectively and you attempted 100 trials. Find the probability (Marginal Probability) of picking up an orange ball.\n","\n","  **Explanation**: The given probability of picking up the balls from the bags are 0.36, 0.28, and 0.44. This means that out of 100 trials, the number of times we will pick the balls from black, white, and grey bags are 36, 28, and 44."]},{"cell_type":"code","metadata":{"id":"WwmF6v2DZ4yX"},"source":["# Number of orange and green balls in black bag\n","o_black = 4\n","g_black = 12\n","\n","# Number of orange and green balls in white bag\n","o_white = 6\n","g_white = 18\n","\n","# Number of orange and green balls in grey bag\n","o_grey = 8\n","g_grey = 24"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VxlxA5OYZ4yi"},"source":["# Given probabilities of picking up the ball from black, white, and grey bags\n","trials = 100\n","p_black = 0.36\n","p_white = 0.28\n","p_grey = 0.44\n","\n","# Out of 100 trials, the number of instances where a ball is picked from black, white and grey bags\n","n_black = p_black*trials\n","n_white = p_white*trials\n","n_grey = p_grey*trials\n","\n","print(n_black)\n","print(n_white)\n","print(n_grey)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RxdSXBrOZ4yq"},"source":["Next, as we want to find the probability of picking up an orange ball, we will first calculate the number of instances where we picked an orange ball from black, white, and grey bags."]},{"cell_type":"code","metadata":{"id":"s6k3gXvxZ4y0"},"source":["ib_orange =  (o_black/(o_black+g_black))*n_black\n","iw_orange = (o_white/(o_white+g_white))*n_white\n","ig_orange = (o_grey/(o_grey+g_grey))*n_grey\n","\n","i_total = ib_orange + iw_orange + ig_orange\n","\n","print(\"No. of instances where we pick orange ball from black bag\\n\",ib_orange)\n","print(\"No. of instances where we pick orange ball from white bag\\n\",iw_orange)\n","print(\"No. of instances where we pick orange ball from grey bag\\n\",ig_orange)\n","print(\"Total instances where we pick orange ball\\n\" ,i_total)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IsQGeFalZ4y6"},"source":["Now, the probability of picking up an orange ball is the sum of probabilities of all the instances where an orange ball is driven out from the bag over the total number of trials."]},{"cell_type":"code","metadata":{"id":"HIl3Xr3aZ4y_"},"source":["marginal_probability = i_total/trials\n","print(marginal_probability)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Measures of Central Tendency and Variability\n","\n","There are three main measures of central tendency: the mode, the median and the mean. Each of these measures describes a different indication of the typical or central value in the distribution.\n","\n","\n","**Mean** \n","\n","The mean is the sum of the value of each observation in a dataset divided by the number of observations. This is also known as the arithmetic average.\n","\n","**Advantage of the mean** : The mean can be used for both continuous and discrete numeric data.\n","\n","**Limitations of the mean** : The mean cannot be calculated for categorical data, as the values cannot be summed.\n","\n","As the mean includes every value in the distribution the mean is influenced by outliers and skewed distributions.\n","\n","\n","**Median** \n","\n","The median is the middle value in distribution when the values are arranged in ascending or descending order.\n","\n","The median divides the distribution in half (there are 50% of observations on either side of the median value). In a distribution with an odd number of observations, the median value is the middle value.\n","\n","**Advantage of the median**: The median is less affected by outliers and skewed data than the mean, and is usually the preferred measure of central tendency when the distribution is not symmetrical.\n","\n","**Limitation of the median**: The median cannot be identified for categorical nominal data, as it cannot be logically ordered.\n","\n","\n","**Mode**\n","\n","The mode is the most commonly occurring value in a distribution.\n","\n","**Advantage of the mode**: The mode has an advantage over the median and the mean as it can be found for both numerical and categorical (non-numerical) data.\n","\n","**Limitations of the mode**: The are some limitations to using the mode. In some distributions, the mode may not reflect the centre of the distribution very well. \n"],"metadata":{"id":"48Aub8JE0CSV"}},{"cell_type":"markdown","source":[" **1.** The retirement age of eleven people are 54, 54, 54, 55, 56, 57, 57, 58, 58, 60, and 60. Find the mean, median and mode for the retirement age."],"metadata":{"id":"AE14RQFMtJ1a"}},{"cell_type":"code","source":["retirement_age = [54, 54, 54, 55, 56, 57, 57, 58, 58, 60, 60]"],"metadata":{"id":"ju4xuumuWJQ5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The mean is calculated by adding together all the values **(54+54+54+55+56+57+57+58+58+60+60 = 623)** and dividing by the number of observations (11. But here we will directly use mean() method of numpy library."],"metadata":{"id":"mdFvKd2aW-0v"}},{"cell_type":"code","source":["np.mean(retirement_age)"],"metadata":{"id":"gd1Az7-EWpeX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["np.median(retirement_age)"],"metadata":{"id":"q-K5V2LuWqOv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["For the above data, the median is the middle value, which is 57 years.\n","\n","But, when the distribution has an even number of observations, the median value is the mean of the two middle values. Consider the following distribution, the two middle values are 56 and 57, therefore the median equals 56.5 years:\n","\n","52, 54, 54, 54, 55, 56, 57, 57, 58, 58, 60, 60"],"metadata":{"id":"OJhR3Qo-dSo9"}},{"cell_type":"code","source":["# Use the mode() function from the statistics module\n","# YOUR CODE HERE"],"metadata":{"id":"8-cxsq-eWpW7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The above `stats.mode()` method returns \n","\n","`mode:` Array of modal values.\n","\n","`count:` Array of counts for each mode.\n","\n","\n","The most commonly occurring value is 54, therefore the mode of this distribution is 54 years.\n","\n","When the distribution of retirement age is ordered from lowest to highest value, it is easy to see that the centre of the distribution is 57 years, but the mode is lower, at 54 years.\n","\n","54, 54, 54, 55, 56, 57, 57, 58, 58, 60, 60\n","\n","It is also possible for there to be more than one mode for the same distribution of data, (bi-modal, or multi-modal). The presence of more than one mode can limit the ability of the mode in describing the centre or typical value of the distribution because a single value to describe the centre cannot be identified.\n","\n","In some cases, particularly where the data are continuous, the distribution may have no mode at all (i.e. if all values are different).\n","\n","In cases such as these, it may be better to consider using the median or mean, or group the data in to appropriate intervals, and find the modal class.\n"],"metadata":{"id":"Y5BM311hffAh"}},{"cell_type":"markdown","source":["**How do outliers influence the measures of central tendency?**\n","\n","**Outliers are extreme, or atypical data value(s) that are notably different from the rest of the data.**\n","\n","It is important to detect outliers within a distribution, because they can alter the results of the data analysis. The mean is more sensitive to the existence of outliers than the median or mode.\n","\n","Consider the initial retirement age dataset again, with one difference; the last observation of 60 years has been replaced with a retirement age of 81 years. This value is much higher than the other values, and could be considered an outlier. However, it has not changed the middle of the distribution, and therefore the median value is still 57 years.\n","\n","54, 54, 54, 55, 56, 57, 57, 58, 58, 60, 81\n","\n","As the all values are included in the calculation of the mean, the outlier will influence the mean value.\n","\n","(54+54+54+55+56+57+57+58+58+60+81 = 644), divided by 11 = 58.5 years\n","\n","In this distribution the outlier value has increased the mean value.\n","\n","Despite the existence of outliers in a distribution, the mean can still be an appropriate measure of central tendency, especially if the rest of the data is normally distributed. If the outlier is confirmed as a valid extreme value, it should not be removed from the dataset. Several common regression techniques can help reduce the influence of outliers on the mean value."],"metadata":{"id":"sdEUcN88fz07"}},{"cell_type":"markdown","source":["### Customer churn dataset"],"metadata":{"id":"7Hfd4C0ifmFx"}},{"cell_type":"markdown","source":["#### About Data\n","\n","This competition is about predicting whether a customer will change telecommunications provider, something known as \"churning\".\n","\n","The dataset contains 4250 samples. Each sample contains 19 features and 1 boolean variable \"churn\" which indicates the class of the sample. The 19 input features and 1 target variable are:\n","\n","1. \"state\", string: 2-letter code of the US state of customer residence\n","2. \"account_length\", numerical: Number of months the customer has been with the current telecom provider\n","3. \"area_code\", string : \"area_code_AAA\" where AAA = 3 digit area code.\n","4. \"international_plan\", (yes/no): The customer has international plan.\n","5. \"voice_mail_plan\", (yes/no): The customer has voice mail plan.\n","6. \"number_vmail_messages\", numerical: Number of voice-mail messages.\n","7. \"total_day_minutes\", numerical: Total minutes of day calls.\n","8. \"total_day_calls\", numerical: Total minutes of day calls.\n","9. \"total_day_charge\", numerical: Total charge of day calls.\n","10. \"total_eve_minutes\", numerical: Total minutes of evening calls.\n","11. \"total_eve_calls\", numerical: Total number of evening calls.\n","12. \"total_eve_charge\", numerical: Total charge of evening calls.\n","13. \"total_night_minutes\", numerical: Total minutes of night calls.\n","14. \"total_night_calls\", numerical: Total number of night calls.\n","15. \"total_night_charge\", numerical: Total charge of night calls.\n","16. \"total_intl_minutes\", numerical: Total minutes of international calls.\n","17. \"total_intl_calls\", numerical: Total number of international calls.\n","18. \"total_intl_charge\", numerical: Total charge of international calls\n","19. \"number_customer_service_calls\", numerical: Number of calls to customer service\n","20. \"churn\", (yes/no): Customer churn - target variable."],"metadata":{"id":"PTnMF4RaMFAk"}},{"cell_type":"markdown","source":["#### Loading the data "],"metadata":{"id":"46CSQxzhNfbI"}},{"cell_type":"code","source":["customer_churn = pd.read_csv('Customer_Churn.csv')"],"metadata":{"id":"eApOwGcexzlW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["customer_churn.head()"],"metadata":{"id":"LwwFIngnyZy3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Basic data preprocessing"],"metadata":{"id":"OVJtl44CNqn_"}},{"cell_type":"code","source":["# Replace 'yes' and 'no' values with '1' and '0'.\n","# YOUR CODE HERE"],"metadata":{"id":"HETtE6BLdh5u"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Let us have a look at the columns after replacing churn values with '1' and '0'."],"metadata":{"id":"inABlIH7jDP6"}},{"cell_type":"code","source":["customer_churn.head()"],"metadata":{"id":"JBcSuhE5wZps"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Numerical Features"],"metadata":{"id":"YFoOXgEgBNcp"}},{"cell_type":"code","source":["numerical= customer_churn.select_dtypes(include = 'number').columns\n","\n","categorical = customer_churn.select_dtypes(include = 'object').columns\n","\n","print(f'Numerical Columns:  {customer_churn[numerical].columns}')\n","print('\\n')\n","print(f'Categorical Columns: {customer_churn[categorical].columns}')"],"metadata":{"id":"Nx45gEOpS5M4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["For ease of usage, we got the list of the numerical and categorical features."],"metadata":{"id":"htFLrswPTxgb"}},{"cell_type":"code","source":["num_col = []\n","\n","for col in numerical:\n","    if customer_churn[col].dtype == \"int64\":\n","        num_col.append(col)\n","\n","num_col.remove(\"churn\")\n","print(num_col)"],"metadata":{"id":"3hWt8rYbBPwc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Convert all types columns (except for churn) with int64 into float type.\n","for i in num_col:\n","  customer_churn[i] = customer_churn[i].astype(float)"],"metadata":{"id":"DriZ4xaiTjup"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Correlation**\n","\n","The correlation is a statistical measure of the strength of the relationship between the relative movements of two variables. We use correlation coefficient to measure the strength of relationship. The values range between -1.0 and 1.0. A calculated number greater than 1.0 or less than -1.0 means that there was an error in the correlation measurement. A correlation of -1.0 shows a perfect negative correlation, while a correlation of 1.0 shows a perfect positive correlation. A correlation of 0.0 shows no linear relationship between the movement of the two variables. \n","\n","**Note:** The correlation we are referring here is Pearson correlation.\n","\n","Some key points related to correlation are:\n","\n","1. Correlation has no units.\n","2. A key mathematical property of the Pearson correlation coefficient is that it is invariant under separate changes in location and scale in the two variables. That is, we may transform $X$ to $a + bX$ and transform $Y$ to $c + dY$, where $a, b, c$ and $d$ are constants with $b, d > 0$, without changing the correlation coefficient.\n","An important limitation of the correlation coefficient is that it assumes a linear association.\n","3. Correlation between two random variables, $\\rho (X,Y)$ is the covariance of the two variables normalized by the variance of each variable. This normalization cancels the units out and normalizes the measure so that it is always in the range [0, 1]:\n","\n","  $\\rho (X, Y) = \\frac{Cov(X, Y)}{\\sqrt{(Var(X)Var(Y))}}$\n","\n","**Example** : Correlation statistics can be used in finance and investing. A correlation coefficient could be calculated to determine the level of correlation between the price of crude oil and the stock price of an oil-producing company, such as Exxon Mobil Corporation. Since oil companies earn greater profits as oil prices rise, the correlation between the two variables is highly positive.\n"],"metadata":{"id":"siXc6xc6LhvT"}},{"cell_type":"markdown","source":["2. Find the features in the customer churn dataset which has the highest correlation. "],"metadata":{"id":"5P2uOZqIZCfF"}},{"cell_type":"code","source":["# Function for correlation plot\n","def correlation_plot():\n","  plt.figure(figsize=(12, 6))\n","  sns.heatmap(customer_churn[numerical].corr(), annot=True, fmt= '.2f', vmin=-1, vmax=1, center=0, cmap='coolwarm');"],"metadata":{"id":"pYAfRWG-UX1_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["correlation_plot()"],"metadata":{"id":"2lSn7Ilid5mW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* We can see in heatmap that we have some multicollinerity.\n","* We need to drop one of each highly correleated column pairs."],"metadata":{"id":"0LhlHFX2U1If"}},{"cell_type":"code","source":["# Dropping the columns\n","drop_col = ['total_day_charge', 'total_eve_charge', 'total_night_charge', 'total_intl_charge']\n","customer_churn = customer_churn.drop(drop_col, axis=1)\n","customer_churn.shape"],"metadata":{"id":"Hm-Z5DjJVGFI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Select the numerical columns from the above data\n","# YOUR CODE HERE"],"metadata":{"id":"SqbAdzxmWH0x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["correlation_plot()"],"metadata":{"id":"Whcdtfr8V5Nz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now, We got rid of multicollinear columns. Here, we can see that `total_day_minutes` has the highest correleation with `churn`.Overall, there is low correleations among features."],"metadata":{"id":"TY_tNhE_YPJ4"}},{"cell_type":"markdown","source":["\n","**Standard Deviation**\n","\n"],"metadata":{"id":"iBYUSckCLwFT"}},{"cell_type":"markdown","source":["3. Find the standard deviation of the feature which is highly correlated with `churn` in the dataset."],"metadata":{"id":"c0NlCZQeb8es"}},{"cell_type":"code","source":["np.std(customer_churn['total_day_minutes'])"],"metadata":{"id":"XO2BhiKeaQrw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZuzPSz6nKazP"},"source":["4. Calculate the variance of the feature which has the second highest correlation with churn.\n"]},{"cell_type":"code","source":["customer_churn.total_eve_minutes.var()"],"metadata":{"id":"HVv4tNcEO2r1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["`Consider another data of employees salaries, number of working hours, and experience in years and answer the below question.`\n","\n","`dataframe = (`\n","\n","`  {'Name': ['Dan', 'Joann', 'Pedro', 'Rosie', 'Ethan', 'Vicky', 'Frederic'],`\n","\n","  `'Salary':[50000, 54000, 50000, 189000, 55000, 40000, 59000],`\n","\n","  `'Hours':[41,40,36,17,35,39,40],`\n","\n","  `'Experience(In Years)':[2, 2, 3, 7, 5, 2, 4]})`\n","\n","\n","\n","\n"],"metadata":{"id":"Aksyz_VjPfzi"}},{"cell_type":"markdown","metadata":{"id":"4OMitShRMLp5"},"source":["5. Calculate the correlation between Salary and Experience(In Years) columns for the employees data given above.\n"]},{"cell_type":"code","metadata":{"id":"mLRHnAdSGLj4"},"source":["# Create a dataframe\n","df = pd.DataFrame({'Name': ['Dan', 'Joann', 'Pedro', 'Rosie', 'Ethan', 'Vicky', 'Frederic'],\n","                   'Salary':[50000, 54000, 50000, 189000, 55000, 40000, 59000],\n","                   'Hours':[41, 40, 36, 17, 35, 39, 40],\n","                   'Experience(In Years)':[2, 2, 3, 7, 5, 2, 4]})"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AqBloFehMU42"},"source":["# Calculate the correlation between Salary and Experience(In Years)\n","# YOUR CODE HERE"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"H5s-vNYRM115"},"source":["6. Find the quartile thresholds for the weekly hours worked by the employees for the above employees data."]},{"cell_type":"code","metadata":{"id":"fIJnRxjNNIvk"},"source":["print(\"The quartile threshold values are\\n\",df['Hours'].quantile([0.25, 0.5, 0.75]))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"W4N56ItzNVE1"},"source":["### Parameter Estimation"]},{"cell_type":"markdown","metadata":{"id":"ps5EQE0TNXQm"},"source":["**Parameter Estimation:** Parameters are defined as the characteristics of the given data. Estimators are defined as the predictions of values with the help of the dataset.\n","\n","Any function of a random sample that is used to estimate the values of the parameter of a given dataset is called Parameter Estimation.\n","\n","If $x_1,x_2,x_3,....x_n$ is the sample size of size n, then\n","\n","$T_n(x_1,x_2,x_3,....x_n)$ will be the estimator of parameter."]},{"cell_type":"markdown","metadata":{"id":"FDwUsYHnNgOw"},"source":["### Bias Estimation"]},{"cell_type":"markdown","metadata":{"id":"TnTNYElJNiMU"},"source":["**Bias Estimation:**  Bias is a term that refers to any type of error or distortion that is found with the use of analysis. Bias Estimation is the difference between the parameter to be estimated and the mathematical expectation of the estimator.\n","\n","$bias(\\hatθ_n)$ = $E[\\hatθ_n]- \\hatθ_n$\n","\n","The estimator is said to be unbiased when expected parameter and the original parameter are same i.e $E[θ_n^|] = θ_n^|.$"]},{"cell_type":"markdown","metadata":{"id":"WjXvsuicNkjC"},"source":["`7.` `Calculate the bias for the below given dataframe.`\n","\n","\n","  `dataframe = {`\n","  \n","  `'Expected_parameter':[2,3,1,5,6,7,8,9,6,5,4,3,2],`\n","\n","  `'Original_parameter':[3,4,3,2,2,4,5,6,9,6,6,4,5]`\n","`}`\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"xzterEgxNoii"},"source":["data = {\n","    'Expected_parameter':[2,3,1,5,6,7,8,9,6,5,4,3,2],\n","    'Original_parameter':[3,4,3,2,2,4,5,6,9,6,6,4,5]\n","}"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataframe = pd.DataFrame(data)\n","dataframe['Bias'] = dataframe['Expected_parameter'] - dataframe[\"Original_parameter\"] # Calculating the bias according to the formula\n","print(\"The bias is\\n\", dataframe[\"Bias\"])"],"metadata":{"id":"lFSV2AN7s98Q"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7z5CKXI3NzeI"},"source":["### Mean Squared Error"]},{"cell_type":"markdown","metadata":{"id":"zoqp2f84Nnz6"},"source":["**Mean Squared Error :** \n","\n","\n","Let $\\hat{X}=g(Y)$ be an estimator of the random variable $X$, given that we have observed the random variable $Y$. The mean squared error (MSE) of this estimator is defined as\n","\n","$E[(X−\\hat{X})^2]=E[(X−g(Y))^2].$\n"]},{"cell_type":"markdown","source":["8. Consider two estimators $E_{1}$  and $E_{2}$ used by two different Machine Learning algorithms.These estimators are used to predict the values using the dataset. If the true values present in the dataset for the predictor variable are [ 1, 1, 2, 2, 4 ] and the values predicted by the two estimators are: $E_{1}$ = [ 0.6, 1.29, 1.99, 2.69, 3.4 ], and $E_{2}$ = [0.45, 1.19 ,1.99 ,1.69, 2.4]. Find out which estimator gives better estimate for prediction."],"metadata":{"id":"QkLuWMemTpqh"}},{"cell_type":"code","metadata":{"id":"5KiW-bNsN9_0"},"source":["# Defining Y_true and Y_pred values\n","Y_true = [1,1,2,2,4]\n","E1_pred = [0.6,1.29,1.99,2.69,3.4]  \n","E2_pred = [0.45, 1.19 ,1.99 ,1.69, 2.4]  \n","\n","# Calculating Mean Squared Error\n","# YOUR CODE HERE\n","\n","print(\"The mean Square Error for Estimator 1 is \",MSE1)\n","print(\"The mean Square Error for Estimator 2 is \",MSE2)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"l6ZMBUuEN_zf"},"source":["### Maximum Likelihood Estimation"]},{"cell_type":"markdown","metadata":{"id":"VjGSs8O9OBwc"},"source":["**Maximum Likelihood Estimation:** Maximum likelihood estimation is a method that determines maximum values for the parameter of a model."]},{"cell_type":"markdown","metadata":{"id":"ZZz5fFwOOEdp"},"source":["9. Build 1000 data points from the normal distribution with  mean = 1 and standard deviation = 5. Estimate their maximum likelihood of mean, variance, and standard deviation from the data."]},{"cell_type":"code","metadata":{"id":"WNLcwPvYOGdS"},"source":["# Building the distributed data from mean and standard deviation\n","mean = 1\n","std = 5\n","N_points = 1000\n","\n","# Finding the random normal distributed data \n","# YOUR CODE HERE"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Inp5af9gOIau"},"source":["# Printing the original mean and variance\n","print('Original mean is '+str(mean) + ', variance is ' + str(std**2),\" and standard deviation is \" +str(std))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JAxlMkzvONuV"},"source":["# Calculate the mean from the data\n","# YOUR CODE HERE"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"frylF700OPSA"},"source":["# Calculating the variance from the data\n","var_ML = (1/(N_points-1)) * sum([(x-mu_ML) ** 2 for x in data])\n","print('Maximum likelihood estimation of variance from the normal distributed data is ' + str(var_ML))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CyJ8_Yi6ORds"},"source":["# Calculate the standard deviation from the data\n","# YOUR CODE HERE"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oBGn2dPCapoZ"},"source":["### Bayesian inference"]},{"cell_type":"markdown","metadata":{"id":"jLsEzKdcar0Q"},"source":["**Bayesian inference :**- Bayesian inference is a method of statistical inference in which Baye's theorem is used to update the probability for a hypothesis as more evidence or information becomes available. Bayesian inference is an important technique in statistics, and especially in mathematical statistics.\n","\n","The core of Bayesian Inference is to combine two different distributions (likelihood and prior) into one “smarter” distribution (posterior). Posterior is **“smarter” in the sense that the classic maximum likelihood estimation (MLE) doesn’t take into account a prior**. Once we calculate the posterior, we use it to find the “best” parameters and the **“best” is in terms of maximizing the posterior probability**, given the data. This process is called Maximum A Posteriori (MAP).\n","\n","Bayesian Inference has three steps.\n","\n","Step 1. **[Prior] Choose a PDF to model your parameter θ**, aka the prior distribution **P(θ)**. This is **your best guess** about parameters **before** seeing the data **X**.\n","\n","Step 2. **[Likelihood] Choose a PDF for $P(X|θ)$**. Basically you are modeling how the data **$X$** will look like given the parameter **$θ$**.\n","\n","Step 3. **[Posterior] Calculate the posterior** distribution **$P(θ|X)$** and pick the **$θ$ that has the highest $P(θ|X)$**.\n","\n","And the posterior becomes the new prior. Repeat step 3 as you get more data.\n","\n","\n","**Formula for calculating Posterior**\n","\n","$P(θ|X) = \\frac{P(X|θ).P(θ)}{\\int P(X|θ).P(θ).dθ}$ \n","\n","where, $P(θ|X)$ = Posterior, $P(X|θ)$ = Sampling, $P(θ)$ = Prior, $dθ$ = Normalizing constant\n","\n","**Note**: We will follow these steps to work on 11th question. "]},{"cell_type":"markdown","metadata":{"id":"LeqpePDLaveP"},"source":["10. Bob is selecting one marble from two bowls of marbles. The first bowl has 75 red marbles and 25 blue marbles. The second bowl has 50 red marbles and 50 blue marbles. Given that Bob is equally likely to choose from either bowl and does not discriminate between the marbles themselves, Bob in fact chooses a red marble. What is the probability Bob picked the marble from bowl 1 and bowl 2? "]},{"cell_type":"code","metadata":{"id":"g6-fP5raayPb"},"source":["# Probability of fetching the marble from bowl\n","P_H_1 = P_H_2 = 0.5 \n","\n","# Probability of fetching the red marble from first bowl\n","P_E_H_1 = 75/100\n","\n","# Probability of fetching the marble from second bowl\n","P_E_H_2 = 50/100\n","\n","# Applying the Bayesian formula to pick the red marble from first bowl\n","# YOUR CODE HERE\n","\n","print(\"The probability of fetching the red marble from bowl 1 is \"+str(P_H_1_E)+ \" and from bowl 2 is \"+str(P_H_2_E))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bTCNpvaZa16i"},"source":["### Prior and Posterior distribution"]},{"cell_type":"markdown","metadata":{"id":"I-2iTwz8a57C"},"source":["**Prior distribution:** \n","A Prior distribution represents your belief about the true or false value of a parameter. It shows your “best guess.”"]},{"cell_type":"markdown","metadata":{"id":"ZvgASXe4a77D"},"source":["**Posterior distribution:**  The posterior distribution summarizes what you know after the data has been observed. The summary of the evidence from the new observations is the likelihood function.\n","It is represented as $Posterior$ $Distribution$ $=$ $Prior$ $Distribution + Likelihood$ $Function (“new$ $evidence”)$"]},{"cell_type":"markdown","source":["11. Consider a scenario, where, an education management company conducts free sessions on YouTube on various topics related to Deep Learning. Everytime a session is conducted, around 4000 people actively attends it. After the experts closes the session, a feedback is asked from the attendees. Some people liked the session and some don't. Now, we would like to make predictions about what percentage of people will engage and like when we conduct a session in the future, so that the company can understand about the potential participants willing to continue learning by enrolling in their professional courses. \n","\n"],"metadata":{"id":"yRLt6LchmNRz"}},{"cell_type":"markdown","source":["Let's generate the data X. "],"metadata":{"id":"GgJFH9rznfm4"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"BP3hxvzLsebe"},"outputs":[],"source":["np.set_printoptions(threshold=100)\n","\n","# Generating 4,000 participants reponse. \n","# Assuming the 'likes' or 'dislikes' follow a Bernoulli process - a sequence of binary (success/failure) random variables.\n","# 1 means liked. 0 means dislike.\n","\n","# We pick the success rate of 30%.\n","liked_prob = 0.3\n","\n","# IID (independent and identically distributed) assumption\n","liked_data = np.random.binomial(n=1, p=liked_prob, size=4000)"]},{"cell_type":"markdown","source":["Let us have a look at liked data."],"metadata":{"id":"9Iu5QZzVogbk"}},{"cell_type":"code","source":["print(liked_data)"],"metadata":{"id":"alGLsVtd1nkz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(liked_data)"],"metadata":{"id":"gES95aP_1sGs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Firstly, we will choose the PDF to model the parameter θ.\n","\n","Note : $\\theta$ is the **'liking'** probability.\n"],"metadata":{"id":"5pxBSfnBqQzL"}},{"cell_type":"markdown","source":["`i) What kind of probability distributions should we use to model a probability?`\n","\n","**Explaination**: Since, we have only one thing to predict, we will use a Beta distribution. It has two parameters, $α$ & $β$, that we need to decide. You can think of $α$ as How many people liked (the number of successes) and $β$ as how many people did’t liked (the number of failures). These parameters — how big or small $α$ & $β$ are — will determine the shape of the distribution."],"metadata":{"id":"KGtDV0WYvWk2"}},{"cell_type":"markdown","source":["`ii) Let us assume that we have 800 people out of 4000 who liked the session. Write this in terms of beta distribution and plot the prior distribution with respect to all` $\\theta$ `values`. "],"metadata":{"id":"TgMS9sfGvufx"}},{"cell_type":"code","source":["# Declaring alpha and beta\n","alpha = 800\n","beta = 4000 - alpha\n","\n","# domain θ\n","theta_range = np.linspace(0, 1, 2000)\n","\n","# prior distribution P(θ)\n","# YOUR CODE HERE"],"metadata":{"id":"kkRa4KY21xA_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Plotting the distribution"],"metadata":{"id":"ZYtL7DFkzTCz"}},{"cell_type":"code","source":["# Plotting the prior distribution\n","plt.rcParams['figure.figsize'] = [20, 7]\n","fig, ax = plt.subplots()\n","plt.plot(theta_range, prior, linewidth=3, color='palegreen')\n","\n","# Add a title\n","plt.title('[Prior] PDF of \"Probability of Claps\"', fontsize=20)\n","\n","# Add X and y Label\n","plt.xlabel('θ', fontsize=16)\n","plt.ylabel('Density', fontsize=16)\n","\n","# Add a grid\n","plt.grid(alpha=.4, linestyle='--')\n","\n","# Show the plot\n","plt.show()"],"metadata":{"id":"hIA9sLIz10Ut"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We can observe from the above plot that it spikes at 20% (800 likes / 4000 participants) as expected."],"metadata":{"id":"mTj_2qES0f-m"}},{"cell_type":"markdown","source":["Further, lets get into step 2 which is Likelihood $P(X|θ)$.\n","\n","Choose a probability model for $P(X|θ)$, the probability of seeing the data $X$ given a particular parameter $θ$. We can also call Likelihood as a sampling distribution."],"metadata":{"id":"fpobrWWr1pqC"}},{"cell_type":"markdown","source":["`iii) Find out which probability distribution should be used to model the sampling distribution and the likelihood?`\n","\n","\n"],"metadata":{"id":"8fZtoqoK68eq"}},{"cell_type":"markdown","source":["**Hint:** Since $X$ is binary, and we also have the total number of participants $(n)$ and we want the probability of liked $(p)$. So, we can use Binomial Distribution with $n$ and $p$."],"metadata":{"id":"L7b4_6F_3VC4"}},{"cell_type":"code","source":["# The sampling dist P(X|θ) with a prior θ\n","# YOUR CODE HERE"],"metadata":{"id":"htP_gOW_15NW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["`iv)` `Plot the graph for` $P(X|θ)$ `for all possible` $θ$.\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n"],"metadata":{"id":"m17Tg1uV4BqI"}},{"cell_type":"code","source":["# Likelihood P(X|θ) for all θ's\n","likelihood = stats.binom.pmf(k = np.sum(liked_data), n = len(liked_data), p = theta_range)\n","\n","# Create the plot\n","fig, ax = plt.subplots()\n","plt.plot(theta_range, likelihood, linewidth=3, color='yellowgreen')\n","\n","# Add a title\n","plt.title('[Likelihood] Probability of people who liked the session' , fontsize=20)\n","\n","# Add X and y Label\n","plt.xlabel('θ', fontsize=16)\n","plt.ylabel('Probability', fontsize=16)\n","\n","# Add a grid\n","plt.grid(alpha=.4, linestyle='--')\n","\n","# Show the plot\n","plt.show()"],"metadata":{"id":"CGkQt0Fc2D9c"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now, we will try to calculate the posterior distribution.\n","\n","Even though there are thousands of data points, we can convert them into a single scalar — the likelihood **$P(X|θ)$ — by plugging data into the model that you choose** (in this example, the binomial distribution).\n","\n","Then, we calculate **$P(θ)$ & $P(X|θ)$** for a specific **$θ$** and multiply them together. If you do this for every possible **$θ$**, you can pick the highest **$P(θ)$ * $P(X|θ)$** among different **$θ’s$**.\n","\n","Your initial guess about parameters was **$P(θ)$**. Now you are **upgrading a simple $P(θ)$ into something more informative — $P(θ|X)$ — as more data become available.**\n","**$P(θ|X)$** is still the probability of **$θ$**, just like **$P(θ)$** is. However, **$P(θ|X)$** is a smarter version of **$P(θ)$**."],"metadata":{"id":"OebbkziVDnMM"}},{"cell_type":"markdown","source":["`v). Calculate the Posterior Distribution` $P(θ|X)$?"],"metadata":{"id":"k2CyayTtH_GV"}},{"cell_type":"code","source":["# Finding the Prior\n","theta_range_e = theta_range + 0.001 \n","\n","# YOUR CODE HERE\n","# prior = stats.beta.pdf(x = theta_range, a=alpha, b=beta)\n","\n","# Finding likelihood\n","likelihood = stats.binom.pmf(k = np.sum(liked_data), n = len(liked_data), p = theta_range) \n","\n","# Element-wise multiplication\n","posterior = likelihood * prior\n","normalized_posterior = posterior / np.sum(posterior)"],"metadata":{"id":"UdWj32-135ep"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Note:** We calculated the prior by subtracting two `stats.beta.cdf` instead of using `stats.beta.pdf` because the likelihood `stats.binom.pmf` is a probability while `stats.beta.pdf` returns a density. Even if we use the density to calculate the posterior, it won’t change the optimization result. However, if you want the units to match, converting a density into a probability is necessary."],"metadata":{"id":"E6jczph5I3gs"}},{"cell_type":"markdown","source":["`vi). Plot the graph for Prior, Likelihood, and Posterior together.`"],"metadata":{"id":"yjbzrjg6HL2u"}},{"cell_type":"code","source":["# Plotting all three together\n","fig, axes = plt.subplots(3, 1, sharex=True, figsize=(20,7))\n","plt.xlabel('θ', fontsize=24)\n","axes[0].plot(theta_range, prior, label=\"Prior\", linewidth=3, color='palegreen')\n","axes[0].set_title(\"Prior\", fontsize=16)\n","axes[1].plot(theta_range, likelihood, label=\"Likelihood\", linewidth=3, color='yellowgreen')\n","axes[1].set_title(\"Sampling (Likelihood)\", fontsize=16)\n","axes[2].plot(theta_range, posterior, label='Posterior', linewidth=3, color='olivedrab')\n","axes[2].set_title(\"Posterior\", fontsize=16)\n","plt.show()"],"metadata":{"id":"wsr9LhoP4F4a"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["When you look at the posterior graph (the 3rd one), **notice it is where the likelihood shifted toward the prior**. The **liked** probability for the prior was 20%. The **liked** probability for the data was given as 30%. Now, the posterior has its peak around 0.25%.\n","\n","Also, notice the width of the bell curves in prior/likelihood has shrunk in the posterior. Because we incorporated more information through sampling, the range of possible parameters is now narrower.\n","\n","The more data you gather, the graph of the posterior will look more like that of the likelihood and less like that of the prior. In other words, as you get more data, the original prior distribution matters less.\n","\n","Finally, we can pick **$\\theta$ that gives the highest posterior** computed by numerical optimization, such as the Gradient Descent or newton method. This whole iterative procedure is called **Maximum A Posteriori estimation (MAP)**."],"metadata":{"id":"hn_DYtKLJOBh"}},{"cell_type":"markdown","metadata":{"id":"Q0vkPqqia-RK"},"source":["12. Construct a prior and posterior distribution with some binominal random distribution techniques."]},{"cell_type":"code","metadata":{"id":"8DQzNpiRbBXD"},"source":["def bern_post(n_params=1000, n_sample=1000, true_p=.5, prior_p=.5, n_prior=1000):\n","    # Creating the samples   \n","    params = np.linspace(0, 1, n_params)\n","    sample = np.random.binomial(n=1, p=true_p, size=n_sample)\n","\n","    # Calculating the Likelihood\n","    # YOUR CODE HERE\n","\n","    # Prior sample\n","    prior_sample = np.random.binomial(n=1, p=prior_p, size=n_prior)\n","    prior = np.array([np.product(stats.bernoulli.pmf(prior_sample, p)) for p in params])\n","    prior = prior / np.sum(prior)\n","\n","    # Finding the posterior  \n","    # YOUR CODE HERE\n","    \n","    # Plotting the graph\n","    fig, axes = plt.subplots(3, 1, sharex=True, figsize=(8,8))\n","    axes[0].plot(params, likelihood)\n","    axes[0].set_title(\"Sampling Distribution\")\n","    axes[1].plot(params, prior)\n","    axes[1].set_title(\"Prior Distribution\")\n","    axes[2].plot(params, posterior)\n","    axes[2].set_title(\"Posterior Distribution\")\n","    sns.despine()\n","    plt.tight_layout()\n","     \n","    return posterior"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"U9eRUzYobFcP"},"source":["moredata_post = bern_post(n_sample=1000)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VHfHdGCP_n6Y"},"source":["### Please answer the questions below to complete the experiment:\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"kmvdJ4aNmGjR"},"source":["#@title Q.1. In a hospital, research show that of patients suffering from a certain illness, 75% die of it. What is the probability that of 6 randomly selected patients, at least one will recover? { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n","Answer1 = \"\" #@param [\"\",\"0.822\", \"0.355\", \"0.2966\", \"0.004395\"]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UX24XAeIJ6Nf"},"source":["#@title Q.2. If X is a continuous random variable with pdf f(x), then what is the relationship between Variance and the Expected value of X? { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n","Answer2 = \"\" #@param [\"\",\"E[X]**2 - E[X**2]\", \"E[X**2] - E[X]**2\", \"E[X**2] - XE[X]\", \"None of the above\"]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NMzKSbLIgFzQ"},"source":["#@title How was the experiment? { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n","Complexity = \"\" #@param [\"\",\"Too Simple, I am wasting time\", \"Good, But Not Challenging for me\", \"Good and Challenging for me\", \"Was Tough, but I did it\", \"Too Difficult for me\"]\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DjcH1VWSFI2l"},"source":["#@title If it was too easy, what more would you have liked to be added? If it was very difficult, what would you have liked to have been removed? { run: \"auto\", display-mode: \"form\" }\n","Additional = \"\" #@param {type:\"string\"}\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4VBk_4VTAxCM"},"source":["#@title Can you identify the concepts from the lecture which this experiment covered? { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n","Concepts = \"\" #@param [\"\",\"Yes\", \"No\"]\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XH91cL1JWH7m"},"source":["#@title  Text and image description/explanation and code comments within the experiment: { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n","Comments = \"\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"z8xLqj7VWIKW"},"source":["#@title Mentor Support: { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n","Mentor_support = \"\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FzAZHt1zw-Y-","cellView":"form"},"source":["#@title Run this cell to submit your notebook for grading { vertical-output: true }\n","try:\n","  if submission_id:\n","      return_id = submit_notebook()\n","      if return_id : submission_id = return_id\n","  else:\n","      print(\"Please complete the setup first.\")\n","except NameError:\n","  print (\"Please complete the setup first.\")"],"execution_count":null,"outputs":[]}]}